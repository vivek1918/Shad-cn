{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b341b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.7.0\n",
      "Uninstalling torch-2.7.0:\n",
      "  Successfully uninstalled torch-2.7.0\n",
      "Found existing installation: transformers 4.52.4\n",
      "Uninstalling transformers-4.52.4:\n",
      "  Successfully uninstalled transformers-4.52.4\n",
      "Found existing installation: trl 0.7.10\n",
      "Uninstalling trl-0.7.10:\n",
      "  Successfully uninstalled trl-0.7.10\n",
      "Found existing installation: accelerate 0.27.2\n",
      "Uninstalling accelerate-0.27.2:\n",
      "  Successfully uninstalled accelerate-0.27.2\n",
      "Found existing installation: peft 0.7.1\n",
      "Uninstalling peft-0.7.1:\n",
      "  Successfully uninstalled peft-0.7.1\n",
      "Found existing installation: bitsandbytes 0.41.3\n",
      "Uninstalling bitsandbytes-0.41.3:\n",
      "  Successfully uninstalled bitsandbytes-0.41.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Skipping torchvision as it is not installed.\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Skipping torchaudio as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement torch==2.1.2 (from versions: 2.2.0+cu118, 2.2.1+cu118, 2.2.2+cu118, 2.3.0+cu118, 2.3.1+cu118, 2.4.0+cu118, 2.4.1+cu118, 2.5.0+cu118, 2.5.1+cu118, 2.6.0+cu118, 2.7.0+cu118)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for torch==2.1.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "# First, completely clean up existing installations\n",
    "!pip uninstall -y torch torchvision torchaudio transformers trl accelerate peft bitsandbytes\n",
    "\n",
    "# Install specific compatible versions\n",
    "!pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install transformers==4.36.2  # Version known to work with trl 0.7.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a884d133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting accelerate==0.27.2\n",
      "  Using cached accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from accelerate==0.27.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from accelerate==0.27.2) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from accelerate==0.27.2) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from accelerate==0.27.2) (6.0.2)\n",
      "Collecting torch>=1.10.0 (from accelerate==0.27.2)\n",
      "  Using cached torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from accelerate==0.27.2) (0.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from accelerate==0.27.2) (0.5.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.10.0->accelerate==0.27.2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.10.0->accelerate==0.27.2) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.10.0->accelerate==0.27.2) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.10.0->accelerate==0.27.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.10.0->accelerate==0.27.2) (2023.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.10.0->accelerate==0.27.2) (75.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub->accelerate==0.27.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub->accelerate==0.27.2) (4.67.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate==0.27.2) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub->accelerate==0.27.2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub->accelerate==0.27.2) (2024.12.14)\n",
      "Using cached accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "Using cached torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "Installing collected packages: torch, accelerate\n",
      "Successfully installed accelerate-0.27.2 torch-2.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "coqui-tts 0.24.3 requires torchaudio>=2.1.0, which is not installed.\n",
      "coqui-tts 0.24.3 requires transformers>=4.43.0, which is not installed.\n",
      "demucs 4.0.1 requires torchaudio>=0.8, which is not installed.\n",
      "encodec 0.1.1 requires torchaudio, which is not installed.\n",
      "facenet-pytorch 2.6.0 requires torchvision<0.18.0,>=0.17.0, which is not installed.\n",
      "lpips 0.1.4 requires torchvision>=0.2.1, which is not installed.\n",
      "openunmix 1.3.0 requires torchaudio>=0.9.0, which is not installed.\n",
      "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, which is not installed.\n",
      "speechbrain 1.0.2 requires torchaudio, which is not installed.\n",
      "timm 1.0.11 requires torchvision, which is not installed.\n",
      "ultralytics 8.3.33 requires opencv-python>=4.6.0, which is not installed.\n",
      "ultralytics 8.3.33 requires torchvision>=0.9.0, which is not installed.\n",
      "unsloth-zoo 2025.5.11 requires peft!=0.11.0,>=0.7.1, which is not installed.\n",
      "unsloth-zoo 2025.5.11 requires transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3, which is not installed.\n",
      "unsloth-zoo 2025.5.11 requires trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9, which is not installed.\n",
      "coqui-tts 0.24.3 requires inflect>=5.6.0, but you have inflect 5.3.0 which is incompatible.\n",
      "coqui-tts 0.24.3 requires librosa>=0.10.1, but you have librosa 0.8.1 which is incompatible.\n",
      "coqui-tts 0.24.3 requires spacy[ja]<3.8,>=3, but you have spacy 3.8.4 which is incompatible.\n",
      "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 10.4.0 which is incompatible.\n",
      "facenet-pytorch 2.6.0 requires torch<2.3.0,>=2.2.0, but you have torch 2.7.0 which is incompatible.\n",
      "unsloth-zoo 2025.5.11 requires accelerate>=0.34.1, but you have accelerate 0.27.2 which is incompatible.\n",
      "unsloth-zoo 2025.5.11 requires datasets>=3.4.1, but you have datasets 2.15.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting peft==0.7.1\n",
      "  Using cached peft-0.7.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.7.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.7.1) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.7.1) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.7.1) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.7.1) (2.7.0)\n",
      "Collecting transformers (from peft==0.7.1)\n",
      "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.7.1) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.7.1) (0.27.2)\n",
      "Requirement already satisfied: safetensors in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.7.1) (0.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from peft==0.7.1) (0.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.13.0->peft==0.7.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.13.0->peft==0.7.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.13.0->peft==0.7.1) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.13.0->peft==0.7.1) (75.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->peft==0.7.1) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from transformers->peft==0.7.1) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from transformers->peft==0.7.1) (0.21.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.7.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch>=1.13.0->peft==0.7.1) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2024.12.14)\n",
      "Using cached peft-0.7.1-py3-none-any.whl (168 kB)\n",
      "Using cached transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "Installing collected packages: transformers, peft\n",
      "Successfully installed peft-0.7.1 transformers-4.52.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "coqui-tts 0.24.3 requires torchaudio>=2.1.0, which is not installed.\n",
      "unsloth-zoo 2025.5.11 requires trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9, which is not installed.\n",
      "coqui-tts 0.24.3 requires inflect>=5.6.0, but you have inflect 5.3.0 which is incompatible.\n",
      "coqui-tts 0.24.3 requires librosa>=0.10.1, but you have librosa 0.8.1 which is incompatible.\n",
      "coqui-tts 0.24.3 requires spacy[ja]<3.8,>=3, but you have spacy 3.8.4 which is incompatible.\n",
      "unsloth-zoo 2025.5.11 requires accelerate>=0.34.1, but you have accelerate 0.27.2 which is incompatible.\n",
      "unsloth-zoo 2025.5.11 requires datasets>=3.4.1, but you have datasets 2.15.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting trl==0.7.10\n",
      "  Using cached trl-0.7.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from trl==0.7.10) (2.7.0)\n",
      "Requirement already satisfied: transformers>=4.31.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from trl==0.7.10) (4.52.4)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from trl==0.7.10) (1.26.4)\n",
      "Requirement already satisfied: accelerate in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from trl==0.7.10) (0.27.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from trl==0.7.10) (2.15.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from trl==0.7.10) (0.9.22)\n",
      "Requirement already satisfied: filelock in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.4.0->trl==0.7.10) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.4.0->trl==0.7.10) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.4.0->trl==0.7.10) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.4.0->trl==0.7.10) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.4.0->trl==0.7.10) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.4.0->trl==0.7.10) (2023.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.4.0->trl==0.7.10) (75.8.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.31.0->trl==0.7.10) (0.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.31.0->trl==0.7.10) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.31.0->trl==0.7.10) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.31.0->trl==0.7.10) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.31.0->trl==0.7.10) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.31.0->trl==0.7.10) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.31.0->trl==0.7.10) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.31.0->trl==0.7.10) (4.67.1)\n",
      "Requirement already satisfied: colorama>=0.4.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from tyro>=0.5.11->trl==0.7.10) (0.4.6)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from tyro>=0.5.11->trl==0.7.10) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from tyro>=0.5.11->trl==0.7.10) (13.8.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from tyro>=0.5.11->trl==0.7.10) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from tyro>=0.5.11->trl==0.7.10) (4.4.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from accelerate->trl==0.7.10) (6.0.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from datasets->trl==0.7.10) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from datasets->trl==0.7.10) (0.7)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from datasets->trl==0.7.10) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from datasets->trl==0.7.10) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from datasets->trl==0.7.10) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from datasets->trl==0.7.10) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from datasets->trl==0.7.10) (3.11.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets->trl==0.7.10) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets->trl==0.7.10) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets->trl==0.7.10) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets->trl==0.7.10) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets->trl==0.7.10) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets->trl==0.7.10) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets->trl==0.7.10) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers>=4.31.0->trl==0.7.10) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers>=4.31.0->trl==0.7.10) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers>=4.31.0->trl==0.7.10) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers>=4.31.0->trl==0.7.10) (2024.12.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.10) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.10) (2.18.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.13.3->torch>=1.4.0->trl==0.7.10) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch>=1.4.0->trl==0.7.10) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets->trl==0.7.10) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets->trl==0.7.10) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets->trl==0.7.10) (2024.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.10) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vivek vasani\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.10) (1.17.0)\n",
      "Using cached trl-0.7.10-py3-none-any.whl (150 kB)\n",
      "Installing collected packages: trl\n",
      "Successfully installed trl-0.7.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Vivek Vasani\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "unsloth-zoo 2025.5.11 requires accelerate>=0.34.1, but you have accelerate 0.27.2 which is incompatible.\n",
      "unsloth-zoo 2025.5.11 requires datasets>=3.4.1, but you have datasets 2.15.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate==0.27.2\n",
    "!pip install peft==0.7.1\n",
    "!pip install trl==0.7.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e178185",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (335394415.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install bitsandbytes==0.41.3\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes==0.41.3\n",
    "!pip install datasets==2.15.0\n",
    "!pip install sentencepiece protobuf huggingface_hub\n",
    "\n",
    "# Restart runtime after installation\n",
    "import os\n",
    "os._exit(00)  # This will restart the runtime in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adedd0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ShadCN Component Generator with LLaMA 3.1 Fine-tuning\n",
    "# Updated version with fixed package versions and error handling\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import platform\n",
    "import json\n",
    "import gc\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --------------------------\n",
    "# Package Installation Setup\n",
    "# --------------------------\n",
    "\n",
    "def check_gpu_info():\n",
    "    \"\"\"Check GPU and CUDA information\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"🎮 GPU Information:\")\n",
    "            lines = result.stdout.split('\\n')\n",
    "            for line in lines:\n",
    "                if 'CUDA Version' in line:\n",
    "                    print(f\"   {line.strip()}\")\n",
    "                elif 'GeForce' in line or 'Tesla' in line or 'Quadro' in line or 'RTX' in line:\n",
    "                    print(f\"   GPU: {line.split('|')[1].strip()}\")\n",
    "            return True\n",
    "    except:\n",
    "        print(\"⚠️ No NVIDIA GPU detected or nvidia-smi not available\")\n",
    "        return False\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install package with error handling\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--no-cache-dir\"])\n",
    "        print(f\"✅ Installed: {package}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to install {package}: {e}\")\n",
    "        return False\n",
    "\n",
    "def uninstall_package(package):\n",
    "    \"\"\"Uninstall package safely\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", package])\n",
    "        print(f\"🗑️ Uninstalled: {package}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def fix_torch_installation():\n",
    "    \"\"\"Fix PyTorch installation with proper CUDA support\"\"\"\n",
    "    print(\"🔧 Fixing PyTorch installation...\")\n",
    "    \n",
    "    # Check if we're in Colab\n",
    "    try:\n",
    "        import google.colab\n",
    "        IN_COLAB = True\n",
    "        print(\"📍 Detected Google Colab environment\")\n",
    "    except:\n",
    "        IN_COLAB = False\n",
    "        print(\"📍 Local environment detected\")\n",
    "    \n",
    "    # Check GPU availability\n",
    "    has_gpu = check_gpu_info()\n",
    "    \n",
    "    # Clean installation\n",
    "    print(\"🧹 Cleaning existing PyTorch installation...\")\n",
    "    packages_to_remove = [\"torch\", \"torchvision\", \"torchaudio\", \"bitsandbytes\", \"transformers\", \"accelerate\", \"peft\", \"trl\"]\n",
    "    for pkg in packages_to_remove:\n",
    "        uninstall_package(pkg)\n",
    "    \n",
    "    # Install PyTorch based on environment\n",
    "    if IN_COLAB:\n",
    "        # Colab typically has CUDA 11.8 or 12.1\n",
    "        print(\"📦 Installing PyTorch for Colab...\")\n",
    "        success = install_package(\"torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118\")\n",
    "        if not success:\n",
    "            # Fallback to CPU version\n",
    "            print(\"⚠️ GPU version failed, installing CPU version...\")\n",
    "            install_package(\"torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\")\n",
    "    else:\n",
    "        # Local installation - try to detect CUDA version\n",
    "        if has_gpu:\n",
    "            print(\"📦 Installing PyTorch with CUDA support...\")\n",
    "            success = install_package(\"torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118\")\n",
    "            if not success:\n",
    "                success = install_package(\"torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
    "            if not success:\n",
    "                print(\"⚠️ CUDA versions failed, installing CPU version...\")\n",
    "                install_package(\"torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\")\n",
    "        else:\n",
    "            print(\"📦 Installing CPU-only PyTorch...\")\n",
    "            install_package(\"torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\")\n",
    "\n",
    "def install_ml_packages():\n",
    "    \"\"\"Install ML packages with version compatibility\"\"\"\n",
    "    print(\"📦 Installing compatible ML packages...\")\n",
    "    \n",
    "    # Core packages with compatible versions\n",
    "    packages = [\n",
    "        \"transformers==4.36.2\",\n",
    "        \"accelerate==0.27.2\",\n",
    "        \"peft==0.7.1\",\n",
    "        \"trl==0.7.10\",\n",
    "        \"datasets==2.15.0\",\n",
    "        \"sentencepiece\",\n",
    "        \"protobuf\",\n",
    "        \"huggingface_hub\",\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        install_package(package)\n",
    "    \n",
    "    # Install bitsandbytes carefully\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"📦 Installing bitsandbytes for GPU...\")\n",
    "            install_package(\"bitsandbytes==0.41.3\")\n",
    "        else:\n",
    "            print(\"📦 Installing bitsandbytes for CPU...\")\n",
    "            install_package(\"bitsandbytes-cpu\")\n",
    "    except:\n",
    "        print(\"⚠️ Installing basic bitsandbytes...\")\n",
    "        install_package(\"bitsandbytes\")\n",
    "\n",
    "# --------------------------\n",
    "# Initial Setup and Checks\n",
    "# --------------------------\n",
    "\n",
    "# Fix installation\n",
    "fix_torch_installation()\n",
    "install_ml_packages()\n",
    "\n",
    "print(\"✅ Installation completed! Testing imports...\")\n",
    "\n",
    "# Test imports with better error handling\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"✅ PyTorch {torch.__version__} imported successfully\")\n",
    "    print(f\"🔍 CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"🔍 CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"🔍 GPU count: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"🔍 GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ PyTorch import failed: {e}\")\n",
    "    print(\"💡 Try restarting runtime and running again\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Import other libraries after installation\n",
    "try:\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
    "    print(\"✅ Transformers imported\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Transformers import failed: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    from datasets import Dataset\n",
    "    print(\"✅ Datasets imported\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Datasets import failed: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "    print(\"✅ PEFT imported\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ PEFT import failed: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    from trl import SFTTrainer\n",
    "    print(\"✅ TRL imported\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ TRL import failed: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Try to import bitsandbytes\n",
    "try:\n",
    "    import bitsandbytes as bnb\n",
    "    QUANTIZATION_AVAILABLE = True\n",
    "    print(\"✅ BitsAndBytes available for quantization\")\n",
    "except Exception as e:\n",
    "    QUANTIZATION_AVAILABLE = False\n",
    "    print(f\"⚠️ BitsAndBytes not available: {e}\")\n",
    "\n",
    "# --------------------------\n",
    "# Configuration\n",
    "# --------------------------\n",
    "\n",
    "MODEL_CONFIGS = {\n",
    "    \"llama3.1-8b\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"llama3.1-8b-4bit\": \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"phi3-mini\": \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    \"qwen2-7b\": \"Qwen/Qwen2-7B-Instruct\",\n",
    "}\n",
    "\n",
    "# Choose model based on available resources\n",
    "if torch.cuda.is_available() and torch.cuda.get_device_properties(0).total_memory > 12e9:  # >12GB VRAM\n",
    "    MODEL_NAME = MODEL_CONFIGS[\"llama3.1-8b-4bit\"]\n",
    "    MAX_SEQ_LENGTH = 2048\n",
    "    BATCH_SIZE = 1\n",
    "    print(\"🎯 Using LLaMA 3.1 8B (4-bit) - High-end setup\")\n",
    "elif torch.cuda.is_available():\n",
    "    MODEL_NAME = MODEL_CONFIGS[\"phi3-mini\"]\n",
    "    MAX_SEQ_LENGTH = 1024\n",
    "    BATCH_SIZE = 1\n",
    "    print(\"🎯 Using Phi-3 Mini - Medium setup\")\n",
    "else:\n",
    "    MODEL_NAME = MODEL_CONFIGS[\"phi3-mini\"]\n",
    "    MAX_SEQ_LENGTH = 512\n",
    "    BATCH_SIZE = 1\n",
    "    print(\"🎯 Using Phi-3 Mini CPU mode - Basic setup\")\n",
    "\n",
    "# Training configuration\n",
    "OUTPUT_DIR = \"./shadcn-component-generator\"\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "MAX_STEPS = 100  # Reduced for testing\n",
    "LEARNING_RATE = 2e-4\n",
    "\n",
    "print(f\"📊 Configuration:\")\n",
    "print(f\"   Model: {MODEL_NAME}\")\n",
    "print(f\"   Max sequence length: {MAX_SEQ_LENGTH}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Max steps: {MAX_STEPS}\")\n",
    "\n",
    "# --------------------------\n",
    "# Dataset and Training Setup\n",
    "# --------------------------\n",
    "\n",
    "def create_sample_dataset():\n",
    "    \"\"\"Create a comprehensive sample dataset for ShadCN components\"\"\"\n",
    "    components_data = [\n",
    "        {\n",
    "            \"component_name\": \"button\",\n",
    "            \"description\": \"Create a versatile button component with multiple variants\",\n",
    "            \"registry_json\": {\n",
    "                \"name\": \"button\",\n",
    "                \"type\": \"component\",\n",
    "                \"dependencies\": [\"class-variance-authority\", \"clsx\"],\n",
    "                \"props\": {\n",
    "                    \"variant\": {\n",
    "                        \"type\": \"enum\",\n",
    "                        \"values\": [\"default\", \"destructive\", \"outline\", \"secondary\", \"ghost\", \"link\"],\n",
    "                        \"default\": \"default\"\n",
    "                    },\n",
    "                    \"size\": {\n",
    "                        \"type\": \"enum\", \n",
    "                        \"values\": [\"default\", \"sm\", \"lg\", \"icon\"],\n",
    "                        \"default\": \"default\"\n",
    "                    }\n",
    "                },\n",
    "                \"css\": {\n",
    "                    \"base\": \"inline-flex items-center justify-center rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50\",\n",
    "                    \"variants\": {\n",
    "                        \"default\": \"bg-primary text-primary-foreground hover:bg-primary/90\",\n",
    "                        \"destructive\": \"bg-destructive text-destructive-foreground hover:bg-destructive/90\",\n",
    "                        \"outline\": \"border border-input bg-background hover:bg-accent hover:text-accent-foreground\",\n",
    "                        \"secondary\": \"bg-secondary text-secondary-foreground hover:bg-secondary/80\",\n",
    "                        \"ghost\": \"hover:bg-accent hover:text-accent-foreground\",\n",
    "                        \"link\": \"text-primary underline-offset-4 hover:underline\"\n",
    "                    },\n",
    "                    \"sizes\": {\n",
    "                        \"default\": \"h-10 px-4 py-2\",\n",
    "                        \"sm\": \"h-9 rounded-md px-3\",\n",
    "                        \"lg\": \"h-11 rounded-md px-8\", \n",
    "                        \"icon\": \"h-10 w-10\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        # ... (rest of your dataset components remain the same)\n",
    "    ]\n",
    "    \n",
    "    return components_data\n",
    "\n",
    "def format_training_prompt(example):\n",
    "    \"\"\"Format training examples for the model\"\"\"\n",
    "    component_name = example[\"component_name\"]\n",
    "    description = example[\"description\"]\n",
    "    registry_json = example[\"registry_json\"]\n",
    "    \n",
    "    prompt = f\"\"\"Create a ShadCN/UI component registry for: {component_name}\n",
    "\n",
    "Description: {description}\n",
    "\n",
    "Component Registry JSON:\n",
    "{json.dumps(registry_json, indent=2)}\"\"\"\n",
    "    \n",
    "    return {\"text\": prompt}\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    \"\"\"Load model and tokenizer with error handling\"\"\"\n",
    "    try:\n",
    "        print(f\"🔄 Loading model: {MODEL_NAME}\")\n",
    "        \n",
    "        # Load tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "        \n",
    "        # Set padding token\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.padding_side = \"right\"\n",
    "        \n",
    "        print(\"✅ Tokenizer loaded\")\n",
    "        \n",
    "        # Configure quantization if available\n",
    "        model_kwargs = {\n",
    "            \"trust_remote_code\": True,\n",
    "            \"torch_dtype\": torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "        }\n",
    "        \n",
    "        if QUANTIZATION_AVAILABLE and torch.cuda.is_available():\n",
    "            bnb_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_compute_dtype=torch.float16,\n",
    "                bnb_4bit_use_double_quant=True\n",
    "            )\n",
    "            model_kwargs[\"quantization_config\"] = bnb_config\n",
    "            model_kwargs[\"device_map\"] = \"auto\"\n",
    "            print(\"✅ Using 4-bit quantization\")\n",
    "        \n",
    "        # Load model\n",
    "        model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, **model_kwargs)\n",
    "        print(\"✅ Model loaded\")\n",
    "        \n",
    "        # Apply LoRA if using quantization\n",
    "        if QUANTIZATION_AVAILABLE and torch.cuda.is_available():\n",
    "            model = prepare_model_for_kbit_training(model)\n",
    "            \n",
    "            peft_config = LoraConfig(\n",
    "                r=16,\n",
    "                lora_alpha=32,\n",
    "                target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "                lora_dropout=0.05,\n",
    "                bias=\"none\",\n",
    "                task_type=\"CAUSAL_LM\"\n",
    "            )\n",
    "            \n",
    "            model = get_peft_model(model, peft_config)\n",
    "            print(\"✅ LoRA configuration applied\")\n",
    "        \n",
    "        return model, tokenizer\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load model: {e}\")\n",
    "        raise\n",
    "\n",
    "def train_model():\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    try:\n",
    "        # Load model and tokenizer\n",
    "        model, tokenizer = load_model_and_tokenizer()\n",
    "        \n",
    "        # Create dataset\n",
    "        print(\"📊 Creating training dataset...\")\n",
    "        sample_data = create_sample_dataset()\n",
    "        formatted_data = [format_training_prompt(example) for example in sample_data]\n",
    "        \n",
    "        # Convert to Dataset object\n",
    "        dataset = Dataset.from_list(formatted_data)\n",
    "        print(f\"✅ Dataset created with {len(dataset)} examples\")\n",
    "        \n",
    "        # Training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=OUTPUT_DIR,\n",
    "            per_device_train_batch_size=BATCH_SIZE,\n",
    "            gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            max_steps=MAX_STEPS,\n",
    "            logging_steps=10,\n",
    "            save_steps=50,\n",
    "            warmup_steps=10,\n",
    "            optim=\"adamw_hf\",\n",
    "            lr_scheduler_type=\"cosine\",\n",
    "            fp16=torch.cuda.is_available(),\n",
    "            dataloader_drop_last=True,\n",
    "            remove_unused_columns=False,\n",
    "            report_to=\"none\",\n",
    "            seed=42,\n",
    "        )\n",
    "        \n",
    "        # Create trainer\n",
    "        trainer = SFTTrainer(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            train_dataset=dataset,\n",
    "            dataset_text_field=\"text\",\n",
    "            max_seq_length=MAX_SEQ_LENGTH,\n",
    "            args=training_args,\n",
    "            packing=False,\n",
    "        )\n",
    "        \n",
    "        print(\"🚀 Starting training...\")\n",
    "        trainer.train()\n",
    "        \n",
    "        # Save model\n",
    "        trainer.save_model(OUTPUT_DIR)\n",
    "        tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "        \n",
    "        print(f\"✅ Training completed! Model saved to {OUTPUT_DIR}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Training failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_generation():\n",
    "    \"\"\"Test component generation\"\"\"\n",
    "    try:\n",
    "        print(\"🧪 Testing component generation...\")\n",
    "        \n",
    "        # Load trained model if available\n",
    "        model_path = OUTPUT_DIR if Path(OUTPUT_DIR).exists() else MODEL_NAME\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=\"auto\" if torch.cuda.is_available() else None\n",
    "        )\n",
    "        \n",
    "        # Test prompts\n",
    "        test_prompts = [\n",
    "            \"Create a badge component with different variants and sizes\",\n",
    "            \"Create a tooltip component with smooth animations\",\n",
    "            \"Create a progress bar component with customizable styling\"\n",
    "        ]\n",
    "        \n",
    "        for prompt in test_prompts:\n",
    "            print(f\"\\n📝 Prompt: {prompt}\")\n",
    "            \n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=300,\n",
    "                    temperature=0.7,\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "            \n",
    "            generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            response = generated_text[len(prompt):].strip()\n",
    "            \n",
    "            print(\"Generated:\")\n",
    "            print(response[:200] + \"...\" if len(response) > 200 else response)\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Generation test failed: {e}\")\n",
    "\n",
    "# --------------------------\n",
    "# Main Execution\n",
    "# --------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🎨 SHADCN COMPONENT GENERATOR WITH LLAMA 3.1\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Run training\n",
    "    success = train_model()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n🎉 Training completed successfully!\")\n",
    "        test_generation()\n",
    "    else:\n",
    "        print(\"\\n❌ Training failed. Check the error messages above.\")\n",
    "    \n",
    "    print(f\"\\n✨ ShadCN Generator ready!\")\n",
    "    print(f\"📁 Model saved in: {OUTPUT_DIR}\")\n",
    "    print(\"🚀 Ready to generate ShadCN components!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
